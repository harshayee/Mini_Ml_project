# -*- coding: utf-8 -*-
"""Mini_ML_Project (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uauJzunH7owSc1aQ2J8lSQKOfd-55yR1
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import pickle

data=pd.read_csv('amazon_alexa.csv')

data.head()

data.describe()

print(data.isnull().sum())

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import string
import re

nltk.download('stopwords')
nltk.download('punkt')

def clean_text(text):
  words = word_tokenize(text)
  stop_words = set(stopwords.words('english'))
  words = [word for word in words if word.lower() not in stop_words]
  words = [word for word in words if word not in string.punctuation]
  words = [word for word in words if not re.match(r'\b\d+(\.\d+)?\b', word)]
  cleaned_text = ' '.join(words)
  return cleaned_text

data = data.dropna(subset=['verified_reviews'])

review_text = data['verified_reviews']
cleaned_reviews = review_text.apply(clean_text)
print(cleaned_reviews)

data['verified_reviews']=cleaned_reviews
data.head()

from nltk.sentiment import SentimentIntensityAnalyzer

nltk.download('vader_lexicon')

sentiments=SentimentIntensityAnalyzer()

def get_sentiment_label(score):
    if score >= 0.05:
        return 'positive'
    elif score <= -0.05:
        return 'negative'
    else:
        return 'neutral'

sentiment_scores = [sentiments.polarity_scores(review)['compound'] for review in cleaned_reviews]
sentiment_labels = [get_sentiment_label(score) for score in sentiment_scores]

data['sentiment'] = sentiment_labels

data.head()

ratings=data['rating'].value_counts()
number=ratings.index
quantity=ratings.values

custom_colors=['skyblue','yellowgreen','tomato','blue','red']
plt.figure(figsize=(5,5))
plt.pie(quantity,labels=number,colors=custom_colors)
central_circle=plt.Circle((0,0),0.5,color='white')
fig=plt.gcf()
fig.gca().add_artist(central_circle)
plt.rc('font',size=12)
plt.title('Amazon Alexa Review',fontsize=20)
plt.show()

X=data['verified_reviews']
y=data['sentiment']

X.value_counts()
y.value_counts()

from sklearn.feature_extraction.text import CountVectorizer

vec = CountVectorizer()

X_vec = vec.fit_transform(X)

from sklearn.model_selection import train_test_split as tts

X_train, X_test, y_train, y_test = tts(X_vec, y, test_size=0.25, random_state=42)

from sklearn.ensemble import RandomForestClassifier

clf=RandomForestClassifier()

clf.fit(X_train,y_train)

predictions = clf.predict(X_test)

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, predictions)

print("Accuracy:",accuracy*100)

new_reviews = ["The Echo is a cool unit, fun to use, but its usefulness depends on the user.",
               "Echo Dot Poor directions for setting up, but if you can get it all figured out it works great with a few quirks",
               "Pretty cool!",
                "Very good, but there is room for improvement.",
                "Very bad quality",
               "Terrible!",
               "bad"]

new_reviews_vec = vec.transform(new_reviews)

new_predictions = clf.predict(new_reviews_vec)

print("Predictions for new reviews:")
for review, prediction in zip(new_reviews, new_predictions):
    print(f"{review}: {prediction}")

from sklearn.svm import SVC

svc_model = SVC(kernel='linear')

svc_model.fit(X_train, y_train)

y_pred = svc_model.predict(X_test)

accuracy1 = accuracy_score(y_test, y_pred)

print("Accuracy:",accuracy1)

pickle.dump(svc_model, open('pra.pkl', 'wb'))

